{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4878b727",
   "metadata": {},
   "source": [
    "1. Processar Dados para Extrair Padr√µes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3364c1",
   "metadata": {},
   "source": [
    "a) Crimes por Hor√°rio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc1a0bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\migue\\AppData\\Local\\Temp\\ipykernel_27404\\1691409007.py:6: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['hora'] = pd.to_datetime(df['hora']).dt.hour\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hor√°rios com mais crimes:\n",
      "    hora  contagem\n",
      "2      2       682\n",
      "11    11       648\n",
      "6      6       647\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('crimes_asa_sul_2020_2025_com_pessoas_endereco2.csv')\n",
    "\n",
    "# Contar crimes por hora\n",
    "df['hora'] = pd.to_datetime(df['hora']).dt.hour\n",
    "crimes_por_hora = df.groupby('hora').size().reset_index(name='contagem')\n",
    "crimes_por_hora = crimes_por_hora.sort_values(by='contagem', ascending=False)\n",
    "print(\"Hor√°rios com mais crimes:\")\n",
    "print(crimes_por_hora.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e59cb1",
   "metadata": {},
   "source": [
    "b) Crimes por Localiza√ß√£o\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "adf3fcb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ruas com mais crimes:\n",
      "       rua  contagem\n",
      "1  CLS 402      1739\n",
      "5  SQS 107      1730\n",
      "3  SQS 105      1719\n"
     ]
    }
   ],
   "source": [
    "# Contar crimes por rua\n",
    "crimes_por_rua = df.groupby('rua').size().reset_index(name='contagem')\n",
    "crimes_por_rua = crimes_por_rua.sort_values(by='contagem', ascending=False)\n",
    "print(\"Ruas com mais crimes:\")\n",
    "print(crimes_por_rua.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab03fbe",
   "metadata": {},
   "source": [
    "    c) Crimes por Tipo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "04a02b40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tipos de crime mais comuns:\n",
      "   tipo_crime  contagem\n",
      "1       furto      4311\n",
      "3       roubo      3323\n",
      "5  vandalismo      2688\n"
     ]
    }
   ],
   "source": [
    "# Contar crimes por tipo\n",
    "crimes_por_tipo = df.groupby('tipo_crime').size().reset_index(name='contagem')\n",
    "crimes_por_tipo = crimes_por_tipo.sort_values(by='contagem', ascending=False)\n",
    "print(\"Tipos de crime mais comuns:\")\n",
    "print(crimes_por_tipo.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1f254d",
   "metadata": {},
   "source": [
    "2. Criar um Modelo de Prioriza√ß√£o Simples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917692e6",
   "metadata": {},
   "source": [
    "a) Calcular Risco por Regi√£o\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7a7aa467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ruas com maior risco:\n",
      "       rua  risco_total\n",
      "1  CLS 402       4527.0\n",
      "3  SQS 105       4526.0\n",
      "5  SQS 107       4414.0\n"
     ]
    }
   ],
   "source": [
    "# Definir pesos por tipo de crime\n",
    "pesos = {\n",
    "    'feminic√≠dio': 5,\n",
    "    'homic√≠dio': 5,\n",
    "    'tr√°fico': 4,\n",
    "    'roubo': 3,\n",
    "    'furto': 2,\n",
    "    'vandalismo': 1\n",
    "}\n",
    "\n",
    "# Adicionar coluna de peso\n",
    "df['peso'] = df['tipo_crime'].map(pesos)\n",
    "\n",
    "# Calcular pontua√ß√£o de risco por rua\n",
    "risco_por_rua = df.groupby('rua')['peso'].sum().reset_index(name='risco_total')\n",
    "risco_por_rua = risco_por_rua.sort_values(by='risco_total', ascending=False)\n",
    "print(\"Ruas com maior risco:\")\n",
    "print(risco_por_rua.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d046d9",
   "metadata": {},
   "source": [
    "b) Identificar Hor√°rios de Risco\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "32944a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hor√°rios com mais crimes graves:\n",
      "   hora  contagem\n",
      "4   4.0       148\n",
      "8   8.0       148\n",
      "9   9.0       145\n"
     ]
    }
   ],
   "source": [
    "# Filtrar crimes graves (ex: homic√≠dio, tr√°fico)\n",
    "crimes_graves = df[df['tipo_crime'].isin(['homic√≠dio', 'tr√°fico'])]\n",
    "\n",
    "# Contar crimes graves por hora\n",
    "horarios_risco = crimes_graves.groupby('hora').size().reset_index(name='contagem')\n",
    "horarios_risco = horarios_risco.sort_values(by='contagem', ascending=False)\n",
    "print(\"Hor√°rios com mais crimes graves:\")\n",
    "print(horarios_risco.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a214b9af",
   "metadata": {},
   "source": [
    "3. Visualizar os Resultados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d0380b67",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Column(s) ['peso'] do not exist\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[45]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m df = pd.read_csv(\u001b[33m'\u001b[39m\u001b[33mcrimes_asa_sul_2020_2025_com_pessoas_endereco.csv\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Calcular risco por rua\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m risco_por_rua = \u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrua\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43magg\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtotal_crimes\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtipo_crime\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcount\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrisco_total\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpeso\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msum\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m)\u001b[49m.reset_index()\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# Calcular m√©dia de coordenadas por rua\u001b[39;00m\n\u001b[32m     15\u001b[39m rua_coords = df.groupby(\u001b[33m'\u001b[39m\u001b[33mrua\u001b[39m\u001b[33m'\u001b[39m)[[\u001b[33m'\u001b[39m\u001b[33mlatitude\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mlongitude\u001b[39m\u001b[33m'\u001b[39m]].mean().reset_index()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\pandas\\core\\groupby\\generic.py:1432\u001b[39m, in \u001b[36mDataFrameGroupBy.aggregate\u001b[39m\u001b[34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[39m\n\u001b[32m   1429\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mengine_kwargs\u001b[39m\u001b[33m\"\u001b[39m] = engine_kwargs\n\u001b[32m   1431\u001b[39m op = GroupByApply(\u001b[38;5;28mself\u001b[39m, func, args=args, kwargs=kwargs)\n\u001b[32m-> \u001b[39m\u001b[32m1432\u001b[39m result = \u001b[43mop\u001b[49m\u001b[43m.\u001b[49m\u001b[43magg\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1433\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_dict_like(func) \u001b[38;5;129;01mand\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1434\u001b[39m     \u001b[38;5;66;03m# GH #52849\u001b[39;00m\n\u001b[32m   1435\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.as_index \u001b[38;5;129;01mand\u001b[39;00m is_list_like(func):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\pandas\\core\\apply.py:190\u001b[39m, in \u001b[36mApply.agg\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    187\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.apply_str()\n\u001b[32m    189\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_dict_like(func):\n\u001b[32m--> \u001b[39m\u001b[32m190\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43magg_dict_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m is_list_like(func):\n\u001b[32m    192\u001b[39m     \u001b[38;5;66;03m# we require a list, but not a 'str'\u001b[39;00m\n\u001b[32m    193\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.agg_list_like()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\pandas\\core\\apply.py:423\u001b[39m, in \u001b[36mApply.agg_dict_like\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    415\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34magg_dict_like\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> DataFrame | Series:\n\u001b[32m    416\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    417\u001b[39m \u001b[33;03m    Compute aggregation in the case of a dict-like argument.\u001b[39;00m\n\u001b[32m    418\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    421\u001b[39m \u001b[33;03m    Result of aggregation.\u001b[39;00m\n\u001b[32m    422\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m423\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43magg_or_apply_dict_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43magg\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\pandas\\core\\apply.py:1608\u001b[39m, in \u001b[36mGroupByApply.agg_or_apply_dict_like\u001b[39m\u001b[34m(self, op_name)\u001b[39m\n\u001b[32m   1603\u001b[39m     kwargs.update({\u001b[33m\"\u001b[39m\u001b[33mengine\u001b[39m\u001b[33m\"\u001b[39m: engine, \u001b[33m\"\u001b[39m\u001b[33mengine_kwargs\u001b[39m\u001b[33m\"\u001b[39m: engine_kwargs})\n\u001b[32m   1605\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m com.temp_setattr(\n\u001b[32m   1606\u001b[39m     obj, \u001b[33m\"\u001b[39m\u001b[33mas_index\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m, condition=\u001b[38;5;28mhasattr\u001b[39m(obj, \u001b[33m\"\u001b[39m\u001b[33mas_index\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1607\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1608\u001b[39m     result_index, result_data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompute_dict_like\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1609\u001b[39m \u001b[43m        \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mselected_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mselection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1610\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1611\u001b[39m result = \u001b[38;5;28mself\u001b[39m.wrap_results_dict_like(selected_obj, result_index, result_data)\n\u001b[32m   1612\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\pandas\\core\\apply.py:462\u001b[39m, in \u001b[36mApply.compute_dict_like\u001b[39m\u001b[34m(self, op_name, selected_obj, selection, kwargs)\u001b[39m\n\u001b[32m    460\u001b[39m is_groupby = \u001b[38;5;28misinstance\u001b[39m(obj, (DataFrameGroupBy, SeriesGroupBy))\n\u001b[32m    461\u001b[39m func = cast(AggFuncTypeDict, \u001b[38;5;28mself\u001b[39m.func)\n\u001b[32m--> \u001b[39m\u001b[32m462\u001b[39m func = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnormalize_dictlike_arg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mselected_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    464\u001b[39m is_non_unique_col = (\n\u001b[32m    465\u001b[39m     selected_obj.ndim == \u001b[32m2\u001b[39m\n\u001b[32m    466\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m selected_obj.columns.nunique() < \u001b[38;5;28mlen\u001b[39m(selected_obj.columns)\n\u001b[32m    467\u001b[39m )\n\u001b[32m    469\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m selected_obj.ndim == \u001b[32m1\u001b[39m:\n\u001b[32m    470\u001b[39m     \u001b[38;5;66;03m# key only used for output\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\pandas\\core\\apply.py:663\u001b[39m, in \u001b[36mApply.normalize_dictlike_arg\u001b[39m\u001b[34m(self, how, obj, func)\u001b[39m\n\u001b[32m    661\u001b[39m     cols = Index(\u001b[38;5;28mlist\u001b[39m(func.keys())).difference(obj.columns, sort=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    662\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(cols) > \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m663\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mColumn(s) \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(cols)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m do not exist\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    665\u001b[39m aggregator_types = (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mdict\u001b[39m)\n\u001b[32m    667\u001b[39m \u001b[38;5;66;03m# if we have a dict of any non-scalars\u001b[39;00m\n\u001b[32m    668\u001b[39m \u001b[38;5;66;03m# eg. {'A' : ['mean']}, normalize all to\u001b[39;00m\n\u001b[32m    669\u001b[39m \u001b[38;5;66;03m# be list-likes\u001b[39;00m\n\u001b[32m    670\u001b[39m \u001b[38;5;66;03m# Cannot use func.values() because arg may be a Series\u001b[39;00m\n",
      "\u001b[31mKeyError\u001b[39m: \"Column(s) ['peso'] do not exist\""
     ]
    }
   ],
   "source": [
    "import folium\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Carregar dados\n",
    "df = pd.read_csv('crimes_asa_sul_2020_2025_com_pessoas_endereco.csv')\n",
    "\n",
    "# Calcular risco por rua\n",
    "risco_por_rua = df.groupby('rua').agg(\n",
    "    total_crimes=('tipo_crime', 'count'),\n",
    "    risco_total=('peso', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "# Calcular m√©dia de coordenadas por rua\n",
    "rua_coords = df.groupby('rua')[['latitude', 'longitude']].mean().reset_index()\n",
    "\n",
    "# Combinar risco com coordenadas\n",
    "risco_com_coords = pd.merge(risco_por_rua, rua_coords, on='rua', how='left')\n",
    "\n",
    "# Criar mapa centrado na Asa Sul\n",
    "mapa = folium.Map(location=[-15.7942, -47.8825], zoom_start=15)\n",
    "\n",
    "# Adicionar marcadores com valida√ß√£o\n",
    "for _, row in risco_com_coords.sort_values(by='risco_total', ascending=False).head(5).iterrows():\n",
    "    lat = row['latitude']\n",
    "    lon = row['longitude']\n",
    "    \n",
    "    # Verificar se as coordenadas s√£o v√°lidas\n",
    "    if pd.notna(lat) and pd.notna(lon):\n",
    "        folium.Marker(\n",
    "            location=[lat, lon],\n",
    "            popup=f\"{row['rua']} (Risco: {row['risco_total']})\",\n",
    "            icon=folium.Icon(color='red', icon='warning')\n",
    "        ).add_to(mapa)\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è Coordenadas inv√°lidas para {row['rua']}\")\n",
    "\n",
    "# Salvar o mapa\n",
    "mapa.save('mapa_risco.html')\n",
    "print(\"‚úÖ Mapa salvo como 'mapa_risco.html'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f0094a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Mapa salvo como 'mapa_interativo_asa_sul.html'\n"
     ]
    }
   ],
   "source": [
    "import folium\n",
    "import pandas as pd\n",
    "from folium.plugins import HeatMap, MarkerCluster\n",
    "\n",
    "# Carregar os dados (amostra de 10% para teste)\n",
    "df = pd.read_csv('crimes_asa_sul_2020_2025_com_pessoas_endereco.csv').sample(n=1500, random_state=42)\n",
    "\n",
    "# Criar mapa centrado na Asa Sul\n",
    "mapa = folium.Map(location=[-15.7942, -47.8825], zoom_start=14, tiles='CartoDB positron')\n",
    "\n",
    "# Adicionar marcadores com clusteriza√ß√£o\n",
    "marker_cluster = MarkerCluster().add_to(mapa)\n",
    "for _, row in df.iterrows():\n",
    "    folium.Marker(\n",
    "        location=[row['latitude'], row['longitude']],\n",
    "        popup=f\"{row['rua']} - {row['tipo_crime']}\",\n",
    "        icon=folium.Icon(color='red', icon='info-sign')\n",
    "    ).add_to(marker_cluster)\n",
    "\n",
    "# Gerar heatmap com amostra menor (10% dos dados)\n",
    "heat_data = [[row['latitude'], row['longitude']] for _, row in df.sample(n=500).iterrows()]\n",
    "HeatMap(heat_data, radius=15, blur=20, max_zoom=16).add_to(mapa)\n",
    "\n",
    "# Salvar o mapa\n",
    "mapa.save('mapa_interativo_asa_sul.html')\n",
    "print(\"‚úÖ Mapa salvo como 'mapa_interativo_asa_sul.html'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915c4ab5",
   "metadata": {},
   "source": [
    "5. Exibir Rotas no Waze ou Google Maps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "082dcb39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîó Rota no Waze: https://waze.com/ul?ll=-15.7932%2C-47.8815&navigate=yes\n"
     ]
    }
   ],
   "source": [
    "# Exemplo de URL para abrir no Waze\n",
    "lat_destino = -15.7932\n",
    "lon_destino = -47.8815\n",
    "url_waze = f\"https://waze.com/ul?ll={lat_destino}%2C{lon_destino}&navigate=yes\"\n",
    "print(\"üîó Rota no Waze:\", url_waze)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
